{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_anycat= pd.read_csv(\"imatinib_data.csv\", nrows=536)\n",
    "df_anycat = df_anycat[df_anycat.columns[:18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anycat['mit_count_na'] = np.where(df_anycat['PRIM_MITOTIC_COUNT_NUMERIC'].isna() == True, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anycat = df_anycat[df_anycat.PRIM_MITOTIC_COUNT_NUMERIC.isna() == False]\n",
    "df_anycat = df_anycat.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Passing time variable to months, to avoid problems\n",
    "df_anycat['Primary_tumor_RFS_months_ima_completion'] = df_anycat['Primary_tumor_RFS_years_ima_completion']*12\n",
    "df_anycat['Primary_tumor_RFS_months'] = df_anycat['Primary_tumor_RFS_years']*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping times 0 to avoid error\n",
    "df_anycat = df_anycat[df_anycat.Primary_tumor_RFS_months_ima_completion > 0.1]\n",
    "df_anycat = df_anycat.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_mc_high = df_anycat['PRIM_MITOTIC_COUNT_NUMERIC'].quantile(0.95)\n",
    "print(cut_mc_high)\n",
    "\n",
    "cut_mc_low = df_anycat['PRIM_MITOTIC_COUNT_NUMERIC'].quantile(0.05)\n",
    "print(cut_mc_low)\n",
    "\n",
    "cut_ts_high = df_anycat['Max_tumor_size'].quantile(0.95)\n",
    "print(cut_ts_high)\n",
    "\n",
    "cut_ts_low = df_anycat['Max_tumor_size'].quantile(0.05)\n",
    "print(cut_ts_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cap mitotic count\n",
    "df_anycat = df_anycat[df_anycat.PRIM_MITOTIC_COUNT_NUMERIC < cut_mc_high]\n",
    "df_anycat = df_anycat.reset_index(drop=True)\n",
    "df_anycat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anycat['PRIM_MITOTIC_COUNT_NUMERIC'].clip(upper=16, inplace=True)\n",
    "\n",
    "## Cap tumor size\n",
    "df_anycat = df_anycat[df_anycat.Max_tumor_size < cut_ts_high]\n",
    "df_anycat = df_anycat.reset_index(drop=True)\n",
    "df_anycat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Risk buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train = df_anycat[df_anycat.Ima_receipt==0]\n",
    "\n",
    "#Z-score normalization (after spliting data, to not leak any information)\n",
    "scaler = StandardScaler()\n",
    "to_train[['Max_tumor_size_norm', 'PRIM_MITOTIC_COUNT_NUMERIC_norm']] = scaler.fit_transform(to_train[['Max_tumor_size', 'PRIM_MITOTIC_COUNT_NUMERIC']])\n",
    "\n",
    "#Selecting variables\n",
    "X = to_train[['Max_tumor_size_norm', 'PRIM_MITOTIC_COUNT_NUMERIC_norm']]\n",
    "y = to_train['Primary_tumor_recurrence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 75],\n",
    "    'max_depth': [3, 5, 7],\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=128)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "accuracy = best_model.score(X, y)\n",
    "print(\"Accuracy on test set:\", accuracy)\n",
    "\n",
    "# Assuming you have predicted probabilities and true labels\n",
    "y_pred_proba = best_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Calculate the AUC-ROC\n",
    "auc = roc_auc_score(y, y_pred_proba)\n",
    "print(\"AUC-ROC:\", auc)\n",
    "\n",
    "# feature importances\n",
    "importances = best_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "print(\"Feature Importance\")\n",
    "for feature, importance in zip(feature_names, importances):\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anycat['rec_score'] = best_model.predict_proba(df_anycat[['Max_tumor_size_norm', 'PRIM_MITOTIC_COUNT_NUMERIC_norm']])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the quartiles\n",
    "q1 = df_anycat['rec_score'].quantile(0.16)\n",
    "q2 = df_anycat['rec_score'].quantile(0.32)\n",
    "q3 = df_anycat['rec_score'].quantile(0.48)\n",
    "q4 = df_anycat['rec_score'].quantile(0.64)\n",
    "q5 = df_anycat['rec_score'].quantile(0.8)\n",
    "\n",
    "# Print the quartiles\n",
    "print(f\"Q1: {q1}\")\n",
    "print(f\"Q2: {q2}\")\n",
    "print(f\"Q3: {q3}\")\n",
    "print(f\"Q4: {q4}\")\n",
    "print(f\"Q5: {q5}\")\n",
    "\n",
    "\n",
    "#Assign buckets\n",
    "conditions = [ df_anycat['rec_score'] <= q1,\n",
    "              (df_anycat['rec_score'] > q1) & (df_anycat['rec_score'] <= q2),\n",
    "              (df_anycat['rec_score'] > q2) & (df_anycat['rec_score'] <= q3),\n",
    "              (df_anycat['rec_score'] > q3) & (df_anycat['rec_score'] <= q4),\n",
    "              (df_anycat['rec_score'] > q4) & (df_anycat['rec_score'] <= q5),\n",
    "              df_anycat['rec_score'] > q5\n",
    "    ]\n",
    "\n",
    "values = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "df_anycat['bucket'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Matching using buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_anycat_0_sampled = pd.DataFrame(columns=df_anycat.columns)\n",
    "df_anycat_1_sampled = pd.DataFrame(columns=df_anycat.columns)\n",
    "\n",
    "samples_bucket_0 = [73, 61, 60, 50, 52, 50]\n",
    "samples_bucket_1 = [2, 6, 6, 18, 18, 32]\n",
    "\n",
    "\n",
    "for bucket in range(1, len(values)+1):\n",
    "    subset_0 = df_anycat[(df_anycat['Ima_receipt'] == 0) & (df_anycat['bucket'] == bucket)].sample(n=samples_bucket_0[bucket-1], replace=False)\n",
    "    subset_1 = df_anycat[(df_anycat['Ima_receipt'] == 1) & (df_anycat['bucket'] == bucket)].sample(n=samples_bucket_1[bucket-1], replace=False)\n",
    "    df_anycat_0_sampled = df_anycat_0_sampled.append(subset_0)\n",
    "    df_anycat_1_sampled = df_anycat_1_sampled.append(subset_1)\n",
    "\n",
    "# Reset the index of the selected_rows DataFrame\n",
    "resulting_data_0_1 = df_anycat_0_sampled.append(df_anycat_1_sampled)\n",
    "resulting_data_0_1.reset_index(drop=True, inplace=True)\n",
    "scaler = MinMaxScaler()\n",
    "resulting_data_norm = scaler.fit_transform(resulting_data_0_1[['Max_tumor_size', 'PRIM_MITOTIC_COUNT_NUMERIC']])\n",
    "resulting_data_0_1_norm = pd.DataFrame(resulting_data_norm, columns=['Max_tumor_size', 'PRIM_MITOTIC_COUNT_NUMERIC'])\n",
    "resulting_data_0_1_norm['bucket'] = resulting_data_0_1['bucket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute distance\n",
    "def dist(p_i, p_j):\n",
    "    squared_diff = 0\n",
    "    if(p_i['treatment'] == p_j['treatment']):\n",
    "        return 100\n",
    "    for k in range(1, len(importances)+1):\n",
    "           squared_diff += importances[k-1] * (p_i[k] - p_j[k])**2\n",
    "#     squared_diff += 0.1 * (p_i['spleen_grade'] - p_j['spleen_grade'])**2\n",
    "    return np.sqrt(squared_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "resulting_data_4 = pd.DataFrame(columns=df_anycat.columns)\n",
    "\n",
    "for k in range(1, len(values)+1):\n",
    "    resulting_data_0_1_k = resulting_data_0_1[resulting_data_0_1['bucket'] == k]\n",
    "    resulting_data_0_1_k_norm = resulting_data_0_1_norm[resulting_data_0_1_norm['bucket'] == k]\n",
    "    resulting_data_0_1_k.reset_index(drop=True, inplace=True)\n",
    "    resulting_data_0_1_k_norm.reset_index(drop=True, inplace=True)\n",
    "    n = len(resulting_data_0_1_k)\n",
    "    print(k)\n",
    "\n",
    "    matrix = cdist(resulting_data_0_1_k_norm,\n",
    "               resulting_data_0_1_k_norm,\n",
    "               metric='euclidean')\n",
    "    print(k)\n",
    "    treat = resulting_data_0_1_k['Ima_receipt']\n",
    "    bucket = resulting_data_0_1_k['bucket']\n",
    "    \n",
    "    #Treatment variable -> df_anycat['imatinib_receipt']\n",
    "\n",
    "    # Create a new model\n",
    "    m = gp.Model()\n",
    "\n",
    "    # Create a 2D array of binary variables\n",
    "    x = m.addVars(n, n, vtype=gp.GRB.BINARY, name=\"x\")\n",
    "\n",
    "    # Set objective function\n",
    "    m.setObjective(gp.quicksum(x[i,j]*matrix[i][j] for i in range(n) for j in range(n)), gp.GRB.MINIMIZE)\n",
    "\n",
    "    # Add constraints\n",
    "    m.addConstrs((gp.quicksum(x[i,j] for j in range(n)) >= treat[i] for i in range(n)), name=\"over_t_i\")\n",
    "    m.addConstrs((gp.quicksum(x[i,j] for i in range(n)) >= treat[j] for j in range(n)), name=\"over_t_j\")\n",
    "\n",
    "    # Add constraints\n",
    "    m.addConstrs((gp.quicksum(x[i,j] for j in range(n)) <= 1 for i in range(n)), name=\"only_one_j2\")\n",
    "    m.addConstrs((gp.quicksum(x[i,j] for i in range(n)) <= 1 for j in range(n)), name=\"only_one_i2\")\n",
    "\n",
    "    #Not two treatments together\n",
    "    m.addConstrs(((treat[i] + treat[j])*x[i,j] <= x[i,j] for i in range(n) for j in range(n)), name=\"not_two\")\n",
    "\n",
    "    #Both points must belong to the same bucket\n",
    "    m.addConstrs((bucket[i]*x[i,j] == bucket[j]*x[i,j] for i in range(n) for j in range(n)), name=\"same_bucket\")\n",
    "\n",
    "    #Not diagonals\n",
    "    m.addConstrs((x[i,i]==0 for i in range(n)), name=\"not_diag\")\n",
    "\n",
    "    # Optimize model\n",
    "    m.optimize()\n",
    "\n",
    "    # Print solution\n",
    "    print(f\"Optimal solution: objective={m.objVal}\")\n",
    "    \n",
    "    x_opt = m.getAttr('x', x)\n",
    "\n",
    "    x_arr = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            x_arr[i][j] = x_opt[i, j]\n",
    "\n",
    "    # Assuming x_opt is a 2D numpy array\n",
    "    row_sums = np.sum(x_arr, axis=1)\n",
    "    resulting_data_4_k = resulting_data_0_1_k[row_sums==1]\n",
    "    resulting_data_4 = resulting_data_4.append(resulting_data_4_k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_data_4 = resulting_data_4.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_data_4.to_csv('imatinib_data_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
